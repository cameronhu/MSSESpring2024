{
 "cells": [
  {
   "cell_type": "markdown",
   "id": "a555d7f0",
   "metadata": {},
   "source": [
    "# Chem 277B Spring 2024 Tutorial 11\n",
    "---\n",
    "## Outline\n",
    "\n",
    "1. Variational Auto-Encoder\n",
    "2. Graph Neural Network"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "id": "27df8ae5",
   "metadata": {},
   "outputs": [],
   "source": [
    "import itertools\n",
    "\n",
    "from tqdm import tqdm\n",
    "import numpy as np\n",
    "import matplotlib.pyplot as plt\n",
    "from sklearn.model_selection import train_test_split\n",
    "\n",
    "import torch\n",
    "import torch.nn as nn"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "13ff7c44",
   "metadata": {},
   "source": [
    "# 1. Variational Auto-Encoder (VAE)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "id": "378af35e",
   "metadata": {},
   "outputs": [],
   "source": [
    "class VAE(nn.Module):\n",
    "    def __init__(self, in_channels=1, z_dim=8):\n",
    "        super().__init__()\n",
    "        self.encoder = nn.Sequential(\n",
    "            # conv1, input_channel -> 4\n",
    "            # relu\n",
    "            # conv2, channel 4 -> 8\n",
    "            # relu\n",
    "            # flatten\n",
    "            nn.Conv2d(in_channels, 4, kernel_size=4, padding=1, stride=2),\n",
    "            nn.ReLU(),\n",
    "            nn.Conv2d(4, 8, kernel_size=4, padding=1, stride=2),\n",
    "            nn.ReLU(),\n",
    "            nn.Flatten()\n",
    "        )\n",
    "        \n",
    "        # manually calculate the dimension after all convolutions\n",
    "        dim_after_conv = 8\n",
    "        hidden_dim = 8 * dim_after_conv * dim_after_conv\n",
    "        \n",
    "        self.readout_mu = nn.Linear(hidden_dim, z_dim)\n",
    "        self.readout_sigma = nn.Linear(hidden_dim, z_dim)\n",
    "        \n",
    "        # You can use nn.ConvTranspose2d to decode\n",
    "        self.decoder = nn.Sequential(\n",
    "            nn.Linear(z_dim, hidden_dim),\n",
    "            nn.Unflatten(1, (8, dim_after_conv, dim_after_conv)),\n",
    "            # transpose-conv, channel 8 -> 4\n",
    "            # relu\n",
    "            # transpose-conv, channel 4 -> input_channel, which is 1\n",
    "            # use a sigmoid activation to squeeze the outputs between 0 and 1\n",
    "            nn.ConvTranspose2d(8, 4, kernel_size=4, stride=2, padding=1),\n",
    "            nn.ReLU(),\n",
    "            nn.ConvTranspose2d(4, in_channels, kernel_size=4, stride=2, padding=1),\n",
    "            nn.Sigmoid(),\n",
    "        )\n",
    "    \n",
    "    def reparameterize(self, mu, sigma):\n",
    "        \"\"\"\n",
    "        Reparameterize, i.e. generate a z ~ N(\\mu, \\sigma)\n",
    "        \"\"\"\n",
    "        # generate epsilon ~ N(0, I)\n",
    "        # hint: use torch.randn or torch.randn_like\n",
    "        epsilon = torch.rand_like(sigma)\n",
    "        # z = \\mu + \\sigma * \\epsilon\n",
    "        z = mu + sigma * epsilon\n",
    "        return z\n",
    "\n",
    "    def encode(self, x):\n",
    "        # call the encoder to map input to a hidden state vector\n",
    "        h = self.encoder(x)\n",
    "        # use the \"readout\" layer to get \\mu and \\sigma\n",
    "        mu = self.readout_mu(h)\n",
    "        sigma = self.readout_sigma(h)\n",
    "        return mu, sigma\n",
    "\n",
    "    def decode(self, z):\n",
    "        # call the decoder to map z back to x\n",
    "        return self.decoder(z)\n",
    "\n",
    "    def forward(self, x):\n",
    "        mu, sigma = self.encode(x)\n",
    "        z = self.reparameterize(mu, sigma)\n",
    "        x_recon = self.decode(z)\n",
    "        return x_recon, mu, sigma"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "id": "0542e7e0",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "4.0"
      ]
     },
     "execution_count": 4,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "128 / 32"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "id": "f7201ffa",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "torch.Size([10, 3, 32, 32])"
      ]
     },
     "execution_count": 5,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "vae = VAE(in_channels=3)\n",
    "x_recon, mu, sigma = vae(torch.rand(10, 3, 32, 32))\n",
    "x_recon.shape"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "4e2b61c5",
   "metadata": {},
   "source": [
    "# 2. Graph Neural Network (GNN)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "id": "8ce714b2",
   "metadata": {},
   "outputs": [],
   "source": [
    "from torch_geometric.datasets import QM9\n",
    "from torch_geometric.loader import DataLoader as GraphDataLoader\n",
    "from torch_geometric.utils import scatter"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "id": "1723d792",
   "metadata": {
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "def load_qm9(path=\"./QM9\"):\n",
    "    def transform(data):\n",
    "        edge_index = torch.tensor(\n",
    "            list(itertools.permutations(range(data.x.shape[0]), 2)), \n",
    "            dtype=torch.long\n",
    "        ).T\n",
    "        edge_feature = 1 / torch.sqrt(\n",
    "            torch.sum(\n",
    "                (data.pos[edge_index[0]] - data.pos[edge_index[1]]) ** 2, \n",
    "                axis=1, keepdim=True\n",
    "            )\n",
    "        )\n",
    "        data.edge_index = edge_index\n",
    "        data.edge_attr = edge_feature\n",
    "        data.y = data.y[:, [-7]]\n",
    "        return data\n",
    "    \n",
    "    qm9 = QM9(path, transform=transform)\n",
    "    return qm9\n",
    "\n",
    "qm9 = load_qm9(\"./QM9\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 26,
   "id": "927515f6",
   "metadata": {},
   "outputs": [],
   "source": [
    "class Layer(nn.Module):\n",
    "    \"\"\"\n",
    "    Basic layer, a linear layer with a ReLU activation \n",
    "    \"\"\"\n",
    "    def __init__(self, in_dim, out_dim):\n",
    "        super().__init__()\n",
    "        self.layers = nn.Sequential(\n",
    "            nn.Linear(in_dim, out_dim), # linear layer\n",
    "            nn.ReLU() # relu\n",
    "        )\n",
    "    \n",
    "    def forward(self, x):\n",
    "        return self.layers(x)\n",
    "    \n",
    "    \n",
    "class MessagePassingLayer(nn.Module):\n",
    "    \"\"\"\n",
    "    A message passing layer that updates nodes/edge features\n",
    "    \"\"\"\n",
    "    def __init__(self, node_hidden_dim, edge_hidden_dim):\n",
    "        super().__init__()\n",
    "        # figure out the input/output dimension\n",
    "        self.edge_net = Layer(2*node_hidden_dim + edge_hidden_dim, edge_hidden_dim)\n",
    "        # figure out the input/output dimension\n",
    "        self.node_net = Layer(node_hidden_dim + edge_hidden_dim, node_hidden_dim)\n",
    "    \n",
    "    def forward(self, node_features, edge_features, edge_index):\n",
    "        \"\"\"\n",
    "        Update node and edge features\n",
    "        \n",
    "        Parameters\n",
    "        ----------\n",
    "        node_features: torch.Tensor\n",
    "            Node features from the previous layer\n",
    "        edge_features: torch.Tensor\n",
    "            Edge features from the previous layer\n",
    "        edge_index: torch.Tensor\n",
    "            A sparse matrix (n_edge, 2) in which each column denotes node indices forming an edge\n",
    "        \"\"\"\n",
    "        # concatnate previous edge features with node features forming the edge\n",
    "        # hint: use edge_features[edge_index[0(or 1)]] to get node features forming the edge\n",
    "        concate_edge_features = torch.cat([\n",
    "            node_features[edge_index[0]], # features of one node\n",
    "            node_features[edge_index[1]], # features of the other node\n",
    "            edge_features # previous edge features\n",
    "        ], dim=1)\n",
    "        \n",
    "        # pass through the \"edge_net\" to map it back to the original dimension\n",
    "        updated_edge_features = self.edge_net(concate_edge_features)\n",
    "        \n",
    "        \n",
    "        # use scatter to aggrate the edge features to nodes\n",
    "        aggr_edge_features = scatter(updated_edge_features, edge_index[0])\n",
    "        # concatenate it with previous node features\n",
    "        concate_node_features = torch.cat([aggr_edge_features, node_features], dim=1)\n",
    "        # pass through the \"node_net\" to map it back to the original dimension\n",
    "        updated_node_features = self.node_net(concate_node_features)\n",
    "        \n",
    "        return updated_node_features, updated_edge_features\n",
    "\n",
    "        \n",
    "class GraphNet(nn.Module):\n",
    "    def __init__(self, node_input_dim, edge_input_dim, node_hidden_dim, edge_hidden_dim):\n",
    "        super().__init__()\n",
    "        # embed the input node features\n",
    "        self.node_embed = Layer(node_input_dim, node_hidden_dim)\n",
    "        # embed the input edge features\n",
    "        self.edge_embed = Layer(edge_input_dim, edge_hidden_dim)\n",
    "        # message passing layer\n",
    "        self.message_passing = MessagePassingLayer(node_hidden_dim, edge_hidden_dim)\n",
    "        # use a linear layer as readout to get the \"atomic\" energy contribution\n",
    "        self.readout = Layer(node_hidden_dim, 1)\n",
    "        \n",
    "    \n",
    "    def forward(self, node_features, edge_features, edge_index, batch):\n",
    "        \"\"\"\n",
    "        Update node and edge features\n",
    "        \n",
    "        Parameters\n",
    "        ----------\n",
    "        node_features: torch.Tensor\n",
    "            Node features from the previous layer\n",
    "        edge_features: torch.Tensor\n",
    "            Edge features from the previous layer\n",
    "        edge_index: torch.Tensor\n",
    "            A sparse matrix (n_edges, 2) in which each column denotes node indices forming an edge\n",
    "        batch: torch.Tensor\n",
    "            A 1-D tensor (n_nodes,) that tells you each node belongs to which graph\n",
    "        \"\"\"\n",
    "        node_hidden = self.node_embed(node_features) # call the node embedding\n",
    "        edge_hidden = self.edge_embed(edge_features) # call the edge embedding\n",
    "        updated_node_hidden, updated_edge_hidden = self.message_passing(node_hidden, edge_hidden, edge_index) # call the message passing layer\n",
    "        readout = self.readout(updated_node_hidden) # use the readout layer to output \"atomic\" contributions\n",
    "        out = scatter(readout, batch) # use the scatter function to aggregate atomic readouts\n",
    "        return out"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 40,
   "id": "c2152c46",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "torch.Size([20, 1])"
      ]
     },
     "execution_count": 40,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "qm9[0].edge_attr.shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 31,
   "id": "474262ff",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "torch.Size([5, 11])"
      ]
     },
     "execution_count": 31,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "qm9[0].x.shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 28,
   "id": "6309d75d",
   "metadata": {},
   "outputs": [],
   "source": [
    "node_input_dim = 11\n",
    "edge_input_dim = 1\n",
    "node_hidden_dim = 64\n",
    "edge_hidden_dim = 64\n",
    "\n",
    "net = GraphNet(node_input_dim, edge_input_dim, node_hidden_dim, edge_hidden_dim)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 29,
   "id": "18368d8b",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "tensor([[0.3001],\n",
       "        [0.1455]], grad_fn=<ScatterAddBackward0>)"
      ]
     },
     "execution_count": 29,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "batch_data = next(iter(GraphDataLoader(qm9[:10], batch_size=2)))\n",
    "batch_pred = net(\n",
    "    batch_data.x, batch_data.edge_attr, \n",
    "    batch_data.edge_index, batch_data.batch\n",
    ")\n",
    "batch_pred"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 30,
   "id": "5c5522df",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "DataBatch(x=[9, 11], edge_index=[2, 32], edge_attr=[32, 1], y=[2, 1], pos=[9, 3], z=[9], smiles=[2], name=[2], idx=[2], batch=[9], ptr=[3])"
      ]
     },
     "execution_count": 30,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "batch_data"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "434a9d06",
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "chem277b",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.10.13"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
