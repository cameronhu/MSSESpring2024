{
 "cells": [
  {
   "cell_type": "markdown",
   "id": "1a4d7e2a",
   "metadata": {},
   "source": [
    "# Checkpoint 2: Network training\n",
    "1. Append the codes in this notebook to Checkpoint 1\n",
    "2. Fill out the ANITrainer class\n",
    "3. Train a model to learn from 2 small datasets (1 heavy atom, and >1 heavy atoms)\n",
    "- Play with the batch size and number of epochs\n",
    "- Aim for RMSE (Root Mean Squared Error) to be less than 5 kcal/mol\n",
    "4. Compare the time between running on CPU and GPU. Here's the suggested workflow\n",
    "- Complete all the code on your laptop and run\n",
    "- Rerun on Savio with GPU to see if the time improves"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "c2c47dc2",
   "metadata": {},
   "outputs": [],
   "source": [
    "import matplotlib.pyplot as plt\n",
    "import time\n",
    "\n",
    "def timeit(f):\n",
    "    def timed(*args, **kw):\n",
    "        ts = time.time()\n",
    "        result = f(*args, **kw)\n",
    "        te = time.time()\n",
    "        print(f'func: {f.__name__} took: {te-ts:.4f} sec on {device}')\n",
    "        return result\n",
    "    return timed\n",
    "\n",
    "class ANITrainer:\n",
    "    def __init__(self, model, batch_size, learning_rate, epoch, l2):\n",
    "        self.model = model\n",
    "        \n",
    "        num_params = sum(item.numel() for item in model.parameters())\n",
    "        print(f\"{model.__class__.__name__} - Number of parameters: {num_params}\")\n",
    "        \n",
    "        self.batch_size = ...\n",
    "        self.optimizer = ...\n",
    "        self.epoch = ...\n",
    "        # definition of loss function: MSE is a good choice! \n",
    "        self.loss_function = ...\n",
    "    \n",
    "    @timeit\n",
    "    def train(self, train_data, val_data, \n",
    "              early_stop=True, draw_curve=True, verbose=True):\n",
    "        self.model.train()\n",
    "        \n",
    "        # init data loader\n",
    "        print(\"Initialize training data...\")\n",
    "        train_data_loader = ...\n",
    "        \n",
    "        # record epoch losses\n",
    "        train_loss_list = []\n",
    "        val_loss_list = []\n",
    "        lowest_val_loss = np.inf\n",
    "        \n",
    "        if verbose:\n",
    "            iterator = range(self.epoch)\n",
    "        else:\n",
    "            iterator = tqdm(range(self.epoch), leave=True)\n",
    "        \n",
    "        for i in iterator:\n",
    "            train_epoch_loss = 0.0\n",
    "            for train_data_batch in train_data_loader:\n",
    "                \n",
    "                # compute energies\n",
    "                ...\n",
    "                \n",
    "                # compute loss\n",
    "                batch_loss = ...\n",
    "                \n",
    "                # do a step\n",
    "                ...\n",
    "                \n",
    "                batch_importance = ...\n",
    "                train_epoch_loss += ...\n",
    "            \n",
    "            # use the self.evaluate to get loss/MAE/RMSE on the validation set \n",
    "            val_epoch_loss, mae, rmse = ...\n",
    "            \n",
    "            # append the losses\n",
    "            ...\n",
    "            \n",
    "            if early_stop:\n",
    "                if val_epoch_loss < lowest_val_loss:\n",
    "                    lowest_val_loss = val_epoch_loss\n",
    "                    weights = self.model.state_dict()\n",
    "        \n",
    "        if draw_curve:\n",
    "            # Plot train loss and validation loss\n",
    "            fig, ax = plt.subplots(1, 1, figsize=(5, 4), constrained_layout=True)\n",
    "            # If you used MSELoss above to compute the loss\n",
    "            # Calculate the RMSE for plotting\n",
    "            ...\n",
    "            ax.plot(..., ..., label='Train')\n",
    "            ax.plot(..., ..., label='Validation')\n",
    "            ax.legend()\n",
    "            ax.set_xlabel(\"Epoch\")\n",
    "            ax.set_ylabel(\"RMSE\")\n",
    "        \n",
    "        if early_stop:\n",
    "            self.model.load_state_dict(weights)\n",
    "        \n",
    "        return train_loss_list, val_loss_list\n",
    "    \n",
    "    \n",
    "    def evaluate(self, data, draw_plot=False):\n",
    "        \n",
    "        # init data loader\n",
    "        data_loader = ...\n",
    "        total_loss = 0.0\n",
    "        \n",
    "        # init energies containers\n",
    "        true_energies_all = []\n",
    "        pred_energies_all = []\n",
    "            \n",
    "        with torch.no_grad():\n",
    "            for batch_data in data_loader:\n",
    "                \n",
    "                # compute energies\n",
    "                ...\n",
    "                \n",
    "                # compute loss\n",
    "                batch_loss = ...\n",
    "\n",
    "                batch_importance = ...\n",
    "                total_loss += ...\n",
    "                \n",
    "                # store true and predicted energies\n",
    "                true_energies_all.append(true_energies.detach().cpu().numpy().flatten())\n",
    "                pred_energies_all.append(pred_energies.detach().cpu().numpy().flatten())\n",
    "        true_energies_all = np.concatenate(true_energies_all)\n",
    "        pred_energies_all = np.concatenate(pred_energies_all)\n",
    "\n",
    "        # Report the mean absolute error (MAE) and root mean square error (RMSE)\n",
    "        # The unit of energies in the dataset is hartree\n",
    "        # please convert it to kcal/mol when reporting\n",
    "        # 1 hartree = 627.5094738898777 kcal/mol\n",
    "        # MAE = mean(|true - pred|)\n",
    "        # RMSE = sqrt(mean( (true-pred)^2 ))\n",
    "        hartree2kcalmol = ...\n",
    "        mae = ... \n",
    "        rmse = ...\n",
    "\n",
    "        if draw_plot:\n",
    "            fig, ax = plt.subplots(1, 1, figsize=(5, 4), constrained_layout=True)\n",
    "            ax.scatter(true_energies_all, pred_energies_all, label=f\"MAE: {mae:.2f} kcal/mol, RMSE: {rmse:.2f} kcal/mol\", s=2)\n",
    "            ax.set_xlabel(\"Ground Truth\")\n",
    "            ax.set_ylabel(\"Predicted\")\n",
    "            xmin, xmax = ax.get_xlim()\n",
    "            ymin, ymax = ax.get_ylim()\n",
    "            vmin, vmax = min(xmin, ymin), max(xmax, ymax)\n",
    "            ax.set_xlim(vmin, vmax)\n",
    "            ax.set_ylim(vmin, vmax)\n",
    "            ax.plot([vmin, vmax], [vmin, vmax], color='red')\n",
    "            ax.legend()\n",
    "            \n",
    "        return total_loss, mae, rmse"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "68878be4",
   "metadata": {},
   "source": [
    "## 1 heavy atom"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "122b56ed",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Load dataset with 1 heavy atom\n",
    "# Then do a train/val/test = 80/10/10 split\n",
    "dataset = load_ani_dataset(\"...\")\n",
    "train_data, val_data, test_data = ...\n",
    "print(f'Train/Total: {len(train_data)}/{len(dataset)}')\n",
    "\n",
    "# Define the model\n",
    "model = nn.Sequential(\n",
    "    aev_computer,\n",
    "    ani_net\n",
    ").to(device)\n",
    "\n",
    "# Initiate the trainer and evaluate on test_dataset with draw_plot=True\n",
    "trainer = ANITrainer(model, ..., 1e-3, ..., 1e-5)\n",
    "loss, mae, rmse = ..."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "9624c2dd",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Run on CPU\n",
    "# Perform training and re-evaluate on test_dataset with draw_plot=True\n",
    "train_losses, val_losses = trainer.train(train_data, val_data, verbose=True)\n",
    "loss, mae, rmse = ..."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "fd30ed4c",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Run on GPU\n",
    "# Perform training and re-evaluate on test_dataset with draw_plot=True\n",
    "train_losses, val_losses = trainer.train(train_data, val_data, verbose=True)\n",
    "loss, mae, rmse = ..."
   ]
  },
  {
   "cell_type": "markdown",
   "id": "933968ae",
   "metadata": {},
   "source": [
    "## n heavy atoms"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "91182498",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Load dataset with n (different from 1) heavy atom\n",
    "# Then do a train/val/test = 80/10/10 split\n",
    "dataset = load_ani_dataset(\"...\")\n",
    "train_data, val_data, test_data = ...\n",
    "print(f'Train/Total: {len(train_data)}/{len(dataset)}')\n",
    "\n",
    "# Define the model\n",
    "model = nn.Sequential(\n",
    "    aev_computer,\n",
    "    ani_net\n",
    ").to(device)\n",
    "\n",
    "# Initiate the trainer and evaluate on test_dataset with draw_plot=True\n",
    "trainer = ANITrainer(model, ..., 1e-3, ..., 1e-5)\n",
    "loss, mae, rmse = ..."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "24c5ed4b",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Run on CPU\n",
    "# Perform training and re-evaluate on test_dataset with draw_plot=True\n",
    "train_losses, val_losses = trainer.train(train_data, val_data, verbose=True)\n",
    "loss, mae, rmse = ..."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "3602ed2e",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Run on GPU\n",
    "# Perform training and re-evaluate on test_dataset with draw_plot=True\n",
    "train_losses, val_losses = trainer.train(train_data, val_data, verbose=True)\n",
    "loss, mae, rmse = ..."
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "chem277b",
   "language": "python",
   "name": "chem277b"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.10.13"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
