{
 "cells": [
  {
   "cell_type": "markdown",
   "id": "a555d7f0",
   "metadata": {},
   "source": [
    "# Chem 277B Spring 2024 Tutorial 11\n",
    "---\n",
    "## Outline\n",
    "\n",
    "1. Variational Auto-Encoder\n",
    "2. Graph Neural Network"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "id": "27df8ae5",
   "metadata": {},
   "outputs": [],
   "source": [
    "import itertools\n",
    "\n",
    "from tqdm import tqdm\n",
    "import numpy as np\n",
    "import matplotlib.pyplot as plt\n",
    "from sklearn.model_selection import train_test_split\n",
    "\n",
    "import torch\n",
    "import torch.nn as nn"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "13ff7c44",
   "metadata": {},
   "source": [
    "# 1. Variational Auto-Encoder (VAE)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "378af35e",
   "metadata": {},
   "outputs": [],
   "source": [
    "class VAE(nn.Module):\n",
    "    def __init__(self, in_channels=1, z_dim=8):\n",
    "        super().__init__()\n",
    "        self.encoder = nn.Sequential(\n",
    "            # conv1, input_channel -> 4\n",
    "            # relu\n",
    "            # conv2, channel 4 -> 8\n",
    "            # relu\n",
    "            # flatten\n",
    "            ...,\n",
    "        )\n",
    "        \n",
    "        # manually calculate the dimension after all convolutions\n",
    "        dim_after_conv = ...\n",
    "        hidden_dim = 8 * dim_after_conv * dim_after_conv\n",
    "        \n",
    "        self.readout_mu = nn.Linear(hidden_dim, z_dim)\n",
    "        self.readout_sigma = nn.Linear(hidden_dim, z_dim)\n",
    "        \n",
    "        # You can use nn.ConvTranspose2d to decode\n",
    "        self.decoder = nn.Sequential(\n",
    "            nn.Linear(z_dim, hidden_dim),\n",
    "            nn.Unflatten(1, (8, dim_after_conv, dim_after_conv)),\n",
    "            # transpose-conv, channel 8 -> 4\n",
    "            # relu\n",
    "            # transpose-conv, channel 4 -> input_channel, which is 1\n",
    "            # use a sigmoid activation to squeeze the outputs between 0 and 1\n",
    "            nn.ConvTranspose2d(8, 4, kernel_size=4, stride=2, padding=1),\n",
    "            ...,\n",
    "        )\n",
    "    \n",
    "    def reparameterize(self, mu, sigma):\n",
    "        \"\"\"\n",
    "        Reparameterize, i.e. generate a z ~ N(\\mu, \\sigma)\n",
    "        \"\"\"\n",
    "        # generate epsilon ~ N(0, I)\n",
    "        # hint: use torch.randn or torch.randn_like\n",
    "        epsilon = ...\n",
    "        # z = \\mu + \\sigma * \\epsilon\n",
    "        z = ...\n",
    "        return z\n",
    "\n",
    "    def encode(self, x):\n",
    "        # call the encoder to map input to a hidden state vector\n",
    "        h = ...\n",
    "        # use the \"readout\" layer to get \\mu and \\sigma\n",
    "        mu = ...\n",
    "        sigma = ...\n",
    "        return mu, sigma\n",
    "\n",
    "    def decode(self, z):\n",
    "        # call the decoder to map z back to x\n",
    "        return ...\n",
    "\n",
    "    def forward(self, x):\n",
    "        mu, sigma = self.encode(x)\n",
    "        z = self.reparameterize(mu, sigma)\n",
    "        x_recon = self.decode(z)\n",
    "        return x_recon, mu, sigma"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "f7201ffa",
   "metadata": {},
   "outputs": [],
   "source": [
    "vae = VAE()\n",
    "x_recon, mu, sigma = vae(torch.rand(10, 1, 32, 32))\n",
    "x_recon.shape"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "4e2b61c5",
   "metadata": {},
   "source": [
    "# 2. Graph Neural Network (GNN)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "id": "8ce714b2",
   "metadata": {},
   "outputs": [],
   "source": [
    "from torch_geometric.datasets import QM9\n",
    "from torch_geometric.loader import DataLoader as GraphDataLoader\n",
    "from torch_geometric.utils import scatter"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "id": "1723d792",
   "metadata": {
    "scrolled": true
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "torch.Size([5, 11])"
      ]
     },
     "execution_count": 12,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "def load_qm9(path=\"./QM9\"):\n",
    "    def transform(data):\n",
    "        edge_index = torch.tensor(\n",
    "            list(itertools.permutations(range(data.x.shape[0]), 2)), \n",
    "            dtype=torch.long\n",
    "        ).T\n",
    "        edge_feature = 1 / torch.sqrt(\n",
    "            torch.sum(\n",
    "                (data.pos[edge_index[0]] - data.pos[edge_index[1]]) ** 2, \n",
    "                axis=1, keepdim=True\n",
    "            )\n",
    "        )\n",
    "        data.edge_index = edge_index\n",
    "        data.edge_attr = edge_feature\n",
    "        data.y = data.y[:, [-7]]\n",
    "        return data\n",
    "    \n",
    "    qm9 = QM9(path, transform=transform)\n",
    "    return qm9\n",
    "\n",
    "qm9 = load_qm9(\"../../Datasets/QM9\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "id": "927515f6",
   "metadata": {},
   "outputs": [],
   "source": [
    "class Layer(nn.Module):\n",
    "    \"\"\"\n",
    "    Basic layer, a linear layer with a ReLU activation \n",
    "    \"\"\"\n",
    "    def __init__(self, in_dim, out_dim):\n",
    "        super().__init__()\n",
    "        self.layers = nn.Sequential(\n",
    "            ..., # linear layer\n",
    "            ... # relu\n",
    "        )\n",
    "    \n",
    "    def forward(self, x):\n",
    "        return self.layers(x)\n",
    "    \n",
    "    \n",
    "class MessagePassingLayer(nn.Module):\n",
    "    \"\"\"\n",
    "    A message passing layer that updates nodes/edge features\n",
    "    \"\"\"\n",
    "    def __init__(self, node_hidden_dim, edge_hidden_dim):\n",
    "        super().__init__()\n",
    "        # figure out the input/output dimension\n",
    "        self.edge_net = Layer(...)\n",
    "        # figure out the input/output dimension\n",
    "        self.node_net = Layer(...)\n",
    "    \n",
    "    def forward(self, node_features, edge_features, edge_index):\n",
    "        \"\"\"\n",
    "        Update node and edge features\n",
    "        \n",
    "        Parameters\n",
    "        ----------\n",
    "        node_features: torch.Tensor\n",
    "            Node features from the previous layer\n",
    "        edge_features: torch.Tensor\n",
    "            Edge features from the previous layer\n",
    "        edge_index: torch.Tensor\n",
    "            A sparse matrix (n_edge, 2) in which each column denotes node indices forming an edge\n",
    "        \"\"\"\n",
    "        # concatnate previous edge features with node features forming the edge\n",
    "        # hint: use edge_features[edge_index[0(or 1)]] to get node features forming the edge\n",
    "        concate_edge_features = torch.cat([\n",
    "            ..., # features of one node\n",
    "            ..., # features of the other node\n",
    "            ... # previous edge features\n",
    "        ], dim=1)\n",
    "        \n",
    "        # pass through the \"edge_net\" to map it back to the original dimension\n",
    "        updated_edge_features = self.edge_net(...)\n",
    "        \n",
    "        \n",
    "        # use scatter to aggrate the edge features to nodes\n",
    "        aggr_edge_features = scatter(...)\n",
    "        # concatenate it with previous node features\n",
    "        concate_node_features = torch.cat([..., ...], dim=1)\n",
    "        # pass through the \"node_net\" to map it back to the original dimension\n",
    "        updated_node_features = self.node_net(...)\n",
    "        \n",
    "        return updated_node_features, updated_edge_features\n",
    "\n",
    "        \n",
    "class GraphNet(nn.Module):\n",
    "    def __init__(self, node_input_dim, edge_input_dim, node_hidden_dim, edge_hidden_dim):\n",
    "        super().__init__()\n",
    "        # embed the input node features\n",
    "        self.node_embed = Layer(...)\n",
    "        # embed the input edge features\n",
    "        self.edge_embed = Layer(...)\n",
    "        # use a linear layer as readout to get the \"atomic\" energy contribution\n",
    "        self.readout = ...\n",
    "        # message passing layer\n",
    "        self.message_passing = MessagePassingLayer(..., ...)\n",
    "    \n",
    "    def forward(self, node_features, edge_features, edge_index, batch):\n",
    "        \"\"\"\n",
    "        Update node and edge features\n",
    "        \n",
    "        Parameters\n",
    "        ----------\n",
    "        node_features: torch.Tensor\n",
    "            Node features from the previous layer\n",
    "        edge_features: torch.Tensor\n",
    "            Edge features from the previous layer\n",
    "        edge_index: torch.Tensor\n",
    "            A sparse matrix (n_edges, 2) in which each column denotes node indices forming an edge\n",
    "        batch: torch.Tensor\n",
    "            A 1-D tensor (n_nodes,) that tells you each node belongs to which graph\n",
    "        \"\"\"\n",
    "        node_hidden = ... # call the node embedding\n",
    "        edge_hidden = ... # call the edge embedding\n",
    "        updated_node_hidden, updated_edge_hidden = ... # call the message passing layer\n",
    "        readout = ... # use the readout layer to output \"atomic\" contributions\n",
    "        out = ... # use the scatter function to aggregate atomic readouts\n",
    "        return out"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "474262ff",
   "metadata": {},
   "outputs": [],
   "source": [
    "qm9[0].x.shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "id": "6309d75d",
   "metadata": {},
   "outputs": [],
   "source": [
    "node_input_dim = ...\n",
    "edge_input_dim = 1\n",
    "node_hidden_dim = 64\n",
    "edge_hidden_dim = 64\n",
    "\n",
    "net = GraphNet(node_input_dim, edge_input_dim, node_hidden_dim, edge_hidden_dim)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "id": "18368d8b",
   "metadata": {},
   "outputs": [],
   "source": [
    "batch_data = next(iter(GraphDataLoader(qm9[:10], batch_size=2)))\n",
    "batch_pred = net(\n",
    "    batch_data.x, batch_data.edge_attr, \n",
    "    batch_data.edge_index, batch_data.batch\n",
    ")\n",
    "batch_pred"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "chem277b",
   "language": "python",
   "name": "chem277b"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.10.13"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
